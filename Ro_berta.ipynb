{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1Ol5tO7dEXvcd8a3Gb5bD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushovitNanda/SemEval-Food-Hazards/blob/main/Ro_berta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vA_DWCFbthuz"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "%%capture\n",
        "#!pip install transformers\n",
        "#!pip install datasets\n",
        "#!pip install torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import DataCollatorWithPadding\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns for richer input data\n",
        "data['combined_text'] = data['title'] + \" \" + data['text']\n",
        "\n",
        "# Encode hazard-category to numerical labels\n",
        "label_mapping = {label: idx for idx, label in enumerate(data['hazard-category'].unique())}\n",
        "data['label'] = data['hazard-category'].map(label_mapping)\n",
        "\n",
        "# Stratified train-test split\n",
        "train_df, val_df = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=42)\n",
        "\n",
        "# Define tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(label_mapping))\n",
        "\n",
        "# Custom Dataset Class for PyTorch\n",
        "class HazardDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = HazardDataset(train_df['combined_text'].tolist(), train_df['label'].tolist(), tokenizer)\n",
        "val_dataset = HazardDataset(val_df['combined_text'].tolist(), val_df['label'].tolist(), tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "total_steps = len(train_loader) * 5  # Assuming 5 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, optimizer, scheduler, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_train_loss = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss}\")\n",
        "\n",
        "        # Validation after each epoch\n",
        "        evaluate_model(model, val_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(classification_report(true_labels, predictions, target_names=label_mapping.keys()))\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgZTyD9uuE18",
        "outputId": "765d808a-f411-4575-a5b4-dc323c190f1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and evaluate the model\n",
        "train_model(model, train_loader, val_loader, optimizer, scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBF6o08BuEzM",
        "outputId": "d912ec40-0c45-4794-b8be-85de80624e22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [01:38<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Training Loss: 0.6784446287681075\n",
            "Validation Classification Report:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                    biological       0.93      0.97      0.95       348\n",
            "                foreign bodies       0.74      0.91      0.82       112\n",
            "                      chemical       0.75      1.00      0.86        57\n",
            "                         fraud       0.90      0.58      0.70        74\n",
            "          organoleptic aspects       0.00      0.00      0.00        11\n",
            "                     allergens       0.94      0.98      0.96       371\n",
            "              packaging defect       0.00      0.00      0.00        11\n",
            "                  other hazard       0.67      0.15      0.24        27\n",
            "food additives and flavourings       0.00      0.00      0.00         5\n",
            "                     migration       0.00      0.00      0.00         1\n",
            "\n",
            "                      accuracy                           0.89      1017\n",
            "                     macro avg       0.49      0.46      0.45      1017\n",
            "                  weighted avg       0.87      0.89      0.87      1017\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [01:35<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Training Loss: 0.27939597788979026\n",
            "Validation Classification Report:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                    biological       0.92      0.98      0.95       348\n",
            "                foreign bodies       0.99      0.88      0.93       112\n",
            "                      chemical       0.90      0.98      0.94        57\n",
            "                         fraud       0.90      0.58      0.70        74\n",
            "          organoleptic aspects       0.80      0.73      0.76        11\n",
            "                     allergens       0.93      0.98      0.95       371\n",
            "              packaging defect       0.73      0.73      0.73        11\n",
            "                  other hazard       0.77      0.63      0.69        27\n",
            "food additives and flavourings       0.00      0.00      0.00         5\n",
            "                     migration       0.00      0.00      0.00         1\n",
            "\n",
            "                      accuracy                           0.92      1017\n",
            "                     macro avg       0.69      0.65      0.67      1017\n",
            "                  weighted avg       0.92      0.92      0.91      1017\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [01:35<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Training Loss: 0.17394748540850832\n",
            "Validation Classification Report:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                    biological       0.94      0.97      0.95       348\n",
            "                foreign bodies       0.94      0.91      0.93       112\n",
            "                      chemical       0.86      1.00      0.93        57\n",
            "                         fraud       0.94      0.65      0.77        74\n",
            "          organoleptic aspects       0.88      0.64      0.74        11\n",
            "                     allergens       0.93      0.99      0.96       371\n",
            "              packaging defect       1.00      0.73      0.84        11\n",
            "                  other hazard       0.77      0.63      0.69        27\n",
            "food additives and flavourings       1.00      0.40      0.57         5\n",
            "                     migration       0.00      0.00      0.00         1\n",
            "\n",
            "                      accuracy                           0.93      1017\n",
            "                     macro avg       0.83      0.69      0.74      1017\n",
            "                  weighted avg       0.93      0.93      0.92      1017\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [01:35<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Training Loss: 0.11919360655706887\n",
            "Validation Classification Report:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                    biological       0.93      0.97      0.95       348\n",
            "                foreign bodies       0.98      0.89      0.93       112\n",
            "                      chemical       0.89      1.00      0.94        57\n",
            "                         fraud       0.94      0.65      0.77        74\n",
            "          organoleptic aspects       0.89      0.73      0.80        11\n",
            "                     allergens       0.94      0.98      0.96       371\n",
            "              packaging defect       0.89      0.73      0.80        11\n",
            "                  other hazard       0.73      0.70      0.72        27\n",
            "food additives and flavourings       0.00      0.00      0.00         5\n",
            "                     migration       0.00      0.00      0.00         1\n",
            "\n",
            "                      accuracy                           0.93      1017\n",
            "                     macro avg       0.72      0.67      0.69      1017\n",
            "                  weighted avg       0.92      0.93      0.92      1017\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [01:35<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Training Loss: 0.0935556901363181\n",
            "Validation Classification Report:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                    biological       0.94      0.97      0.95       348\n",
            "                foreign bodies       0.93      0.91      0.92       112\n",
            "                      chemical       0.88      1.00      0.93        57\n",
            "                         fraud       0.90      0.70      0.79        74\n",
            "          organoleptic aspects       0.80      0.73      0.76        11\n",
            "                     allergens       0.95      0.98      0.97       371\n",
            "              packaging defect       1.00      0.73      0.84        11\n",
            "                  other hazard       0.86      0.70      0.78        27\n",
            "food additives and flavourings       1.00      0.40      0.57         5\n",
            "                     migration       0.00      0.00      0.00         1\n",
            "\n",
            "                      accuracy                           0.93      1017\n",
            "                     macro avg       0.83      0.71      0.75      1017\n",
            "                  weighted avg       0.93      0.93      0.93      1017\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MgDN6wWuEwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}