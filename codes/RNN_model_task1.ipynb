{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv('incidents_labelled.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1r4zMIpdohR",
        "outputId": "0a1fc1f6-b8d7-461d-875c-f5a0f7db8148"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply text preprocessing to the title column\n",
        "train_data['cleaned_title'] = train_data['title'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize the cleaned_title column\n",
        "tokenizer = Tokenizer(num_words=5000)  # Limit vocabulary to top 5000 words\n",
        "tokenizer.fit_on_texts(train_data['cleaned_title'].values)\n",
        "\n",
        "# Convert texts to sequences of integers\n",
        "X = tokenizer.texts_to_sequences(train_data['cleaned_title'].values)\n",
        "\n",
        "# Padding sequences to ensure uniform input length\n",
        "X = pad_sequences(X, maxlen=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "RZZGoB-da7ic"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Converting hazard-category to binary format using LabelBinarizer (for multi-class classification)\n",
        "lb_hazard = LabelBinarizer()\n",
        "y_hazard = lb_hazard.fit_transform(train_data['hazard-category'])\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train_hazard, y_val_hazard = train_test_split(X, y_hazard, test_size=0.2, random_state=42, stratify=y_product)\n",
        "\n",
        "# RNN model using LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5001, output_dim=128, input_length=100))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(lb_hazard.classes_), activation='softmax'))  # Softmax for multi-class classification as it determines\n",
        "# probability distribution over multiple classes, and we want to select the most probable class.\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# Train the RNN model\n",
        "hazard_train = model.fit(\n",
        "    X_train, y_train_hazard,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, y_val_hazard),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predict on validation set for hazard-category\n",
        "y_pred_hazard = model.predict(X_val)\n",
        "y_pred_hazard_classes = np.argmax(y_pred_hazard, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAKJh51ChET5",
        "outputId": "ecabf1fd-7d7a-437a-dd97-4af8b5b0e62e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 470ms/step - accuracy: 0.4317 - loss: 1.7408 - val_accuracy: 0.6266 - val_loss: 1.1348\n",
            "Epoch 2/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.6635 - loss: 1.0134 - val_accuracy: 0.7009 - val_loss: 0.9130\n",
            "Epoch 3/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 240ms/step - accuracy: 0.7766 - loss: 0.7152 - val_accuracy: 0.7510 - val_loss: 0.8256\n",
            "Epoch 4/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 289ms/step - accuracy: 0.8477 - loss: 0.5331 - val_accuracy: 0.7477 - val_loss: 0.8346\n",
            "Epoch 5/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 438ms/step - accuracy: 0.8787 - loss: 0.3954 - val_accuracy: 0.7694 - val_loss: 0.8273\n",
            "Epoch 6/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 294ms/step - accuracy: 0.9142 - loss: 0.3033 - val_accuracy: 0.7786 - val_loss: 0.8742\n",
            "Epoch 6: early stopping\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report for hazard-category\n",
        "classification_rep_hazard = classification_report(np.argmax(y_val_hazard, axis=1), y_pred_hazard_classes, target_names=lb_hazard.classes_)\n",
        "print(\"Classification Report for Hazard-Category:\")\n",
        "print(classification_rep_hazard)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT08Peh4hLPu",
        "outputId": "2942068a-aea1-4ba8-d179-d48fc956272d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Hazard-Category:\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                     allergens       0.86      0.85      0.85       374\n",
            "                    biological       0.81      0.92      0.86       406\n",
            "                      chemical       0.66      0.64      0.65       108\n",
            "food additives and flavourings       0.50      0.17      0.25         6\n",
            "                foreign bodies       0.65      0.70      0.67       152\n",
            "                         fraud       0.73      0.55      0.63        89\n",
            "                     migration       0.00      0.00      0.00         4\n",
            "          organoleptic aspects       0.00      0.00      0.00        13\n",
            "                  other hazard       0.59      0.46      0.52        37\n",
            "              packaging defect       1.00      0.12      0.22         8\n",
            "\n",
            "                      accuracy                           0.78      1197\n",
            "                     macro avg       0.58      0.44      0.46      1197\n",
            "                  weighted avg       0.77      0.78      0.77      1197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert product-category to binary format using LabelBinarizer\n",
        "lb_product = LabelBinarizer()\n",
        "y_product = lb_product.fit_transform(train_data['product-category'])\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_val, y_train_product, y_val_product = train_test_split(X, y_product, test_size=0.2, random_state=42, stratify=y_product)\n",
        "\n",
        "# RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5001, output_dim=128, input_length=100))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(lb_product.classes_), activation='softmax'))  # Softmax for multi-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "product_train = model.fit(\n",
        "    X_train, y_train_product,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, y_val_product),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predict on validation set for product-category\n",
        "y_pred_product = model.predict(X_val)\n",
        "y_pred_product_classes = np.argmax(y_pred_product, axis=1)\n",
        "\n",
        "# Ensure that we include all unique labels from y_val and predictions\n",
        "unique_classes = unique_labels(np.argmax(y_val_product, axis=1), y_pred_product_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETs6wnXWiJga",
        "outputId": "0cd6818c-7a9f-4450-a286-0cfa61249677"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 253ms/step - accuracy: 0.2582 - loss: 2.6241 - val_accuracy: 0.2832 - val_loss: 2.3164\n",
            "Epoch 2/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - accuracy: 0.3267 - loss: 2.2176 - val_accuracy: 0.4127 - val_loss: 1.9579\n",
            "Epoch 3/10\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 226ms/step - accuracy: 0.4525 - loss: 1.8034 - val_accuracy: 0.5104 - val_loss: 1.6504\n",
            "Epoch 3: early stopping\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report with the correct labels\n",
        "classification_rep_product = classification_report(\n",
        "    np.argmax(y_val_product, axis=1),\n",
        "    y_pred_product_classes,\n",
        "    target_names=[lb_product.classes_[i] for i in unique_classes],  # Use only the unique classes\n",
        "    labels=unique_classes\n",
        ")\n",
        "\n",
        "print(\"Classification Report for Product-Category:\")\n",
        "print(classification_rep_product)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW-WURbPjNT8",
        "outputId": "16cd2c89-2bf9-42ec-80c9-a63a78aae016"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Product-Category:\n",
            "                                                   precision    recall  f1-score   support\n",
            "\n",
            "                              alcoholic beverages       0.00      0.00      0.00        15\n",
            "                      cereals and bakery products       0.30      0.84      0.44       156\n",
            "     cocoa and cocoa preparations, coffee and tea       0.35      0.24      0.29        49\n",
            "                                    confectionery       0.00      0.00      0.00        39\n",
            "dietetic foods, food supplements, fortified foods       0.00      0.00      0.00        34\n",
            "                                    fats and oils       0.00      0.00      0.00         4\n",
            "                                   feed materials       0.00      0.00      0.00         1\n",
            "                   food additives and flavourings       0.00      0.00      0.00         2\n",
            "                           food contact materials       0.00      0.00      0.00         5\n",
            "                            fruits and vegetables       0.54      0.60      0.57       131\n",
            "                                 herbs and spices       0.00      0.00      0.00        35\n",
            "                            honey and royal jelly       0.00      0.00      0.00         2\n",
            "                                ices and desserts       0.76      0.67      0.71        46\n",
            "                     meat, egg and dairy products       0.78      0.88      0.83       338\n",
            "                          non-alcoholic beverages       1.00      0.03      0.06        34\n",
            "                     nuts, nut products and seeds       0.30      0.50      0.37        64\n",
            "                       other food product / mixed       0.00      0.00      0.00        13\n",
            "                                         pet feed       0.00      0.00      0.00         4\n",
            "                       prepared dishes and snacks       0.50      0.17      0.25       103\n",
            "                                          seafood       1.00      0.13      0.24        60\n",
            "             soups, broths, sauces and condiments       0.50      0.07      0.12        61\n",
            "                                sugars and syrups       0.00      0.00      0.00         1\n",
            "\n",
            "                                         accuracy                           0.51      1197\n",
            "                                        macro avg       0.27      0.19      0.18      1197\n",
            "                                     weighted avg       0.53      0.51      0.45      1197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3DSsNTYjQ4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}