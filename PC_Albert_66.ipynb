{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5oEIIu3Ydt1soSivjnmVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushovitNanda/SemEval-Food-Hazards/blob/main/PC_Albert_66.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WWXoTYRafolE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets --upgrade\n",
        "#!pip install torch\n",
        "import os\n",
        "import pandas as pd\n",
        "!pip install evaluate\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_train.csv\n",
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_val.csv"
      ],
      "metadata": {
        "id": "w1w8pnEpf6ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input data\n",
        "train['input_text'] = train['title'] + \" \" + train['text']\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['label'] = label_encoder.fit_transform(train['product-category'])\n",
        "\n",
        "# Train-test split using stratification\n",
        "train_df, test_df = train_test_split(\n",
        "    train[['input_text', 'label']],\n",
        "    test_size=0.2,\n",
        "    stratify=train['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert the dataframes into Hugging Face's Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the ALBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "# Define a tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set up a data collator to pad inputs dynamically\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load ALBERT model for sequence classification\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"albert-base-v2\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Load the F1 metric and specify macro averaging\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define the compute_metrics function to maximize F1 macro average\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Compute the F1 macro average\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# Update training arguments to focus on F1 score\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=15,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score as the metric for saving best model\n",
        "    greater_is_better=True       # Ensure higher F1 is considered better\n",
        ")\n",
        "\n",
        "# Redefine the Trainer with the updated compute_metrics and early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics  # Use F1 macro for evaluation\n",
        ")\n",
        "\n",
        "# Add EarlyStoppingCallback to the Trainer with patience of 4 epochs\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4))"
      ],
      "metadata": {
        "id": "kunKzAXhgARb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "2Sm_x7WzgQMQ",
        "outputId": "6d068eff-f045-460e-ec66-1c21582a3c51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6108' max='7635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6108/7635 1:28:12 < 22:03, 1.15 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.317100</td>\n",
              "      <td>1.389121</td>\n",
              "      <td>0.363707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.082900</td>\n",
              "      <td>1.072417</td>\n",
              "      <td>0.456099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.990594</td>\n",
              "      <td>0.506945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.439200</td>\n",
              "      <td>1.023439</td>\n",
              "      <td>0.500048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.361400</td>\n",
              "      <td>0.946413</td>\n",
              "      <td>0.572157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.139900</td>\n",
              "      <td>0.995698</td>\n",
              "      <td>0.602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.312600</td>\n",
              "      <td>1.114721</td>\n",
              "      <td>0.644261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>1.299137</td>\n",
              "      <td>0.663787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.090400</td>\n",
              "      <td>1.360107</td>\n",
              "      <td>0.649971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>1.374309</td>\n",
              "      <td>0.663617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>1.514007</td>\n",
              "      <td>0.651619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>1.522350</td>\n",
              "      <td>0.648641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6108, training_loss=0.477272845471989, metrics={'train_runtime': 5294.616, 'train_samples_per_second': 11.516, 'train_steps_per_second': 1.442, 'total_flos': 1167222216264720.0, 'train_loss': 0.477272845471989, 'epoch': 12.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Classification report\n",
        "target_names = label_encoder.classes_\n",
        "print(classification_report(test_df['label'], preds, target_names=target_names))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "ot9EyDV7nrpJ",
        "outputId": "4515a577-6378-4671-b311-c58ee074f4a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   precision    recall  f1-score   support\n",
            "\n",
            "                              alcoholic beverages       0.86      1.00      0.92        12\n",
            "                      cereals and bakery products       0.75      0.83      0.79       134\n",
            "     cocoa and cocoa preparations, coffee and tea       0.70      0.71      0.71        42\n",
            "                                    confectionery       0.64      0.47      0.54        34\n",
            "dietetic foods, food supplements, fortified foods       0.73      0.73      0.73        26\n",
            "                                    fats and oils       1.00      0.75      0.86         4\n",
            "                                   feed materials       0.00      0.00      0.00         1\n",
            "                   food additives and flavourings       0.00      0.00      0.00         2\n",
            "                           food contact materials       0.00      0.00      0.00         1\n",
            "                            fruits and vegetables       0.88      0.79      0.83       107\n",
            "                                 herbs and spices       0.81      0.68      0.74        25\n",
            "                            honey and royal jelly       1.00      1.00      1.00         2\n",
            "                                ices and desserts       0.97      0.89      0.93        44\n",
            "                     meat, egg and dairy products       0.85      0.90      0.88       287\n",
            "                          non-alcoholic beverages       0.81      0.81      0.81        27\n",
            "                     nuts, nut products and seeds       0.77      0.79      0.78        52\n",
            "                       other food product / mixed       1.00      0.18      0.31        11\n",
            "                                         pet feed       1.00      0.50      0.67         4\n",
            "                       prepared dishes and snacks       0.47      0.52      0.49        94\n",
            "                                          seafood       0.89      0.91      0.90        54\n",
            "             soups, broths, sauces and condiments       0.73      0.72      0.72        53\n",
            "                                sugars and syrups       1.00      1.00      1.00         1\n",
            "\n",
            "                                         accuracy                           0.78      1017\n",
            "                                        macro avg       0.72      0.64      0.66      1017\n",
            "                                     weighted avg       0.78      0.78      0.78      1017\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXxw1ltKnv6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}