{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMiYTL10LwQZ0Pxl7LGpeK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushovitNanda/SemEval-Food-Hazards/blob/main/ML_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fwDqZX1naXI2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.sparse import vstack\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_train.csv\n",
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_val.csv"
      ],
      "metadata": {
        "id": "uzwxWlDDad7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "test = pd.read_csv('incidents_val.csv')\n",
        "\n",
        "# Combine title and text columns into a single feature\n",
        "train['combined_text'] = train['title'] + ' ' + train['text']\n",
        "test['combined_text'] = test['title'] + ' ' + test['text']\n",
        "\n",
        "# Encode target variables\n",
        "label_encoder_hazard = LabelEncoder()\n",
        "label_encoder_product = LabelEncoder()\n",
        "\n",
        "train['hazard_encoded'] = label_encoder_hazard.fit_transform(train['hazard'])\n",
        "train['product_encoded'] = label_encoder_product.fit_transform(train['product'])\n",
        "\n",
        "# Define features (X) and targets (y)\n",
        "X = train['combined_text']\n",
        "y_hazard = train['hazard_encoded']\n",
        "y_product = train['product_encoded']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_val, y_hazard_train, y_hazard_val = train_test_split(\n",
        "    X, y_hazard, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_product_train, y_product_val = train_test_split(\n",
        "    X, y_product, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF feature extraction\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test['combined_text'])\n",
        "\n",
        "# GridSearchCV for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "grid_search_hazard = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search_product = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "6THGdFC5fHQR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train separate classifiers for hazard and product\n",
        "print(\"Tuning hyperparameters for hazard prediction...\")\n",
        "grid_search_hazard.fit(X_train_tfidf, y_hazard_train)\n",
        "print(\"Best parameters for hazard:\", grid_search_hazard.best_params_)\n",
        "\n",
        "print(\"Tuning hyperparameters for product prediction...\")\n",
        "grid_search_product.fit(X_train_tfidf, y_product_train)\n",
        "print(\"Best parameters for product:\", grid_search_product.best_params_)\n",
        "\n",
        "classifier_hazard = grid_search_hazard.best_estimator_\n",
        "classifier_product = grid_search_product.best_estimator_"
      ],
      "metadata": {
        "id": "qvXhrN3ynke0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation scores\n",
        "cv_scores_hazard = cross_val_score(classifier_hazard, X_train_tfidf, y_hazard_train, cv=5, scoring='accuracy')\n",
        "cv_scores_product = cross_val_score(classifier_product, X_train_tfidf, y_product_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"\\nHazard Cross-Validation Accuracy:\", np.mean(cv_scores_hazard))\n",
        "print(\"Product Cross-Validation Accuracy:\", np.mean(cv_scores_product))\n",
        "\n",
        "# Final evaluation on validation set\n",
        "classifier_hazard.fit(X_train_tfidf, y_hazard_train)\n",
        "classifier_product.fit(X_train_tfidf, y_product_train)\n",
        "\n",
        "y_hazard_pred = classifier_hazard.predict(X_val_tfidf)\n",
        "y_product_pred = classifier_product.predict(X_val_tfidf)"
      ],
      "metadata": {
        "id": "T1QY-dkTnxea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Results\n"
      ],
      "metadata": {
        "id": "5rrKV99eoJGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hazard Classification Report:\")\n",
        "print(classification_report(y_hazard_val, y_hazard_pred, target_names=label_encoder_hazard.classes_))"
      ],
      "metadata": {
        "id": "LmnhJJxTnz6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nProduct Classification Report:\")\n",
        "print(classification_report(y_product_val, y_product_pred, target_names=label_encoder_product.classes_))"
      ],
      "metadata": {
        "id": "iENmueyjoCc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "test['hazard_prediction'] = label_encoder_hazard.inverse_transform(classifier_hazard.predict(X_test_tfidf))\n",
        "test['product_prediction'] = label_encoder_product.inverse_transform(classifier_product.predict(X_test_tfidf))\n",
        "\n",
        "# Save predictions to submission.csv\n",
        "test[['hazard_prediction', 'product_prediction']].to_csv('submission.csv', index=False)\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "id": "BRnzCh6OoCWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}