{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modules and Dataset"
      ],
      "metadata": {
        "id": "0mb4Uv4Pij0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uFS21MQ4x2rC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RBF03Tbm1r3M"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "trainset = pd.read_csv('incidents_labelled.csv', index_col=0)\n",
        "testset = pd.read_csv('incidents_val.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomSearchCV for mlp"
      ],
      "metadata": {
        "id": "dasPGUAfToZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf_mlp = Pipeline([\n",
        "    ('vect', TfidfVectorizer(strip_accents='unicode', analyzer='char', ngram_range=(2, 5), max_df=0.5, min_df=5)),\n",
        "    ('clf', MLPClassifier(random_state=42, max_iter=500))  # MLPClassifier with no hyperparameters set yet\n",
        "])"
      ],
      "metadata": {
        "id": "C7OZ9eMBTuPL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter distribution for RandomizedSearchCV\n",
        "param_dist_mlp = {\n",
        "    'clf__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  # Different configurations of hidden layers\n",
        "    'clf__activation': ['tanh', 'relu'],  # Activation functions to explore\n",
        "    'clf__solver': ['adam', 'sgd'],  # Solvers to explore\n",
        "    'clf__alpha': uniform(0.0001, 0.01),  # Regularization parameter\n",
        "    'clf__learning_rate': ['constant', 'adaptive'],  # Learning rate strategies\n",
        "    'clf__learning_rate_init': uniform(0.0001, 0.1)  # Initial learning rate\n",
        "}"
      ],
      "metadata": {
        "id": "btPyl7eQTxRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_mlp(label):\n",
        "    # Split the trainset into training and validation sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(trainset['title'], trainset[label], test_size=0.2, random_state=42)\n",
        "\n",
        "    # RandomizedSearchCV instance for hyperparameter tuning\n",
        "    random_search_mlp = RandomizedSearchCV(text_clf_mlp, param_distributions=param_dist_mlp, n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring='f1_macro')\n",
        "\n",
        "    # Fit the model on the training data with hyperparameter tuning\n",
        "    random_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = random_search_mlp.predict(X_test)\n",
        "\n",
        "    # Print best parameters and classification report\n",
        "    print(f\"Best parameters for {label}: {random_search_mlp.best_params_}\\n\")\n",
        "    print(f\"Classification report for {label}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "54h3xXCyTxOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model for each label\n",
        "for label in ('hazard-category', 'product-category'):\n",
        "    train_and_evaluate_mlp(label)"
      ],
      "metadata": {
        "id": "kuUICuGUTxLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomSearchCV of RF"
      ],
      "metadata": {
        "id": "d9b_RdqpOQP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf_rf = Pipeline([\n",
        "    ('vect', TfidfVectorizer(strip_accents='unicode', analyzer='char', ngram_range=(2, 5), max_df=0.5, min_df=5)),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42)),  # RandomForest with 100 trees\n",
        "])"
      ],
      "metadata": {
        "id": "9WM4OQPJOYY6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'clf__n_estimators': randint(100, 500),  # Try a range between 100 and 500 trees\n",
        "    'clf__max_depth': [None, 10, 20, 30, 40],  # Explore different tree depths\n",
        "    'clf__min_samples_split': randint(2, 10),  # Minimum samples to split a node\n",
        "    'clf__min_samples_leaf': randint(1, 10),  # Minimum samples for a leaf node\n",
        "    'clf__bootstrap': [True, False]  # Whether bootstrap sampling is used\n",
        "}"
      ],
      "metadata": {
        "id": "j2Vsqf2KQrgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(label):\n",
        "    # Split the trainset into training and validation sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(trainset['title'], trainset[label], test_size=0.2, random_state=42)\n",
        "\n",
        "    # RandomizedSearchCV instance for hyperparameter tuning\n",
        "    random_search = RandomizedSearchCV(text_clf_rf, param_distributions=param_dist, n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring='f1_macro')\n",
        "\n",
        "    # Fit the model on the training data with hyperparameter tuning\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Print best parameters and classification report\n",
        "    print(f\"Best parameters for {label}: {random_search.best_params_}\\n\")\n",
        "    print(f\"Classification report for {label}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "4B2jr1R4OEPP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model for each label\n",
        "for label in ('hazard', 'product'):\n",
        "    train_and_evaluate(label)"
      ],
      "metadata": {
        "id": "HuhxyZEwOgCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# downloading predictions and saving it"
      ],
      "metadata": {
        "id": "31rJZ5D4a4Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ('hazard-category', 'product-category'):\n",
        "    text_clf_nn.fit(trainset['title'], trainset[label])\n",
        "    predictions[label] = text_clf_nn.predict(testset['title'])"
      ],
      "metadata": {
        "id": "TIzuz61ybZhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame()\n",
        "for label in ('hazard', 'product'):\n",
        "    text_clf_rf.fit(trainset['title'], trainset[label])\n",
        "    predictions[label] = text_clf_rf.predict(testset['title'])"
      ],
      "metadata": {
        "id": "ywsa3x1_a9sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCmxTGWv1rre",
        "outputId": "66ebb629-304e-41a0-9db4-10375899ffc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved and zipped successfully in SemEval-Hazard folder.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from shutil import make_archive\n",
        "\n",
        "output_folder = r'C:\\Users\\Sushovit\\Desktop\\RF'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Save the predictions to a CSV file inside the \"SemEval-Hazard\" folder\n",
        "csv_path = os.path.join(output_folder, 'submission.csv')\n",
        "predictions.to_csv(csv_path)\n",
        "\n",
        "# Zip the folder and save the zip file inside the \"SemEval-Hazard\" folder\n",
        "zip_path = os.path.join(output_folder, 'submission')\n",
        "make_archive(zip_path, 'zip', output_folder)\n",
        "\n",
        "print(\"Predictions saved and zipped successfully in SemEval-Hazard folder.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0mb4Uv4Pij0z",
        "31rJZ5D4a4Iy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}