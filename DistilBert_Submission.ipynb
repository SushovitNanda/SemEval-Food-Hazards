{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMbMMKAltUoyqJ3dwAnjQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a8485737d34406ea9959acf57a23a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9484e451fe2473eb3ef9194d341746d",
              "IPY_MODEL_b4752608eb0e4ac1bba8f35c42030a23",
              "IPY_MODEL_5980f2a795f34aea86a22e92883d4d7b"
            ],
            "layout": "IPY_MODEL_b7df35aaf2504aa1aa30b185fc160f44"
          }
        },
        "f9484e451fe2473eb3ef9194d341746d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ffff11c1ec405a98c9f3cd387508fd",
            "placeholder": "​",
            "style": "IPY_MODEL_7a7aa6f4853a4d59adfd1a7d3789f7d7",
            "value": "Map: 100%"
          }
        },
        "b4752608eb0e4ac1bba8f35c42030a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e943066a0f4447779812166fc78e4023",
            "max": 4065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0162154dcdef475ab8ff760367f96e26",
            "value": 4065
          }
        },
        "5980f2a795f34aea86a22e92883d4d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5778cce64ad74e409f8a3149d17be549",
            "placeholder": "​",
            "style": "IPY_MODEL_397e49aa76e34c979f771062bbd60860",
            "value": " 4065/4065 [00:37&lt;00:00, 105.52 examples/s]"
          }
        },
        "b7df35aaf2504aa1aa30b185fc160f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ffff11c1ec405a98c9f3cd387508fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7aa6f4853a4d59adfd1a7d3789f7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e943066a0f4447779812166fc78e4023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0162154dcdef475ab8ff760367f96e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5778cce64ad74e409f8a3149d17be549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397e49aa76e34c979f771062bbd60860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b638e322f494714a69798a0eabf99b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce2c9f9046d94b65a24e39e24c1b4860",
              "IPY_MODEL_169a615aab0d4b278b59c078d4935ff8",
              "IPY_MODEL_673f280a79514c938dea6d1b8234311c"
            ],
            "layout": "IPY_MODEL_980fd6ea2121423280a855a90982aff3"
          }
        },
        "ce2c9f9046d94b65a24e39e24c1b4860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6e447b10064ad7b9eb2bac06d36263",
            "placeholder": "​",
            "style": "IPY_MODEL_5c5fa9399eeb41d095ef2e27553f8413",
            "value": "Map: 100%"
          }
        },
        "169a615aab0d4b278b59c078d4935ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71eecc7d13ea4bf095db0797e82aa5ea",
            "max": 1017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1af9f52ecc943dcbbeb958c4cc95df6",
            "value": 1017
          }
        },
        "673f280a79514c938dea6d1b8234311c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed81990eeb144e8f82de84e32efd0e66",
            "placeholder": "​",
            "style": "IPY_MODEL_b8e3680fd03a4e9682ec949c298a9bec",
            "value": " 1017/1017 [00:09&lt;00:00, 106.54 examples/s]"
          }
        },
        "980fd6ea2121423280a855a90982aff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6e447b10064ad7b9eb2bac06d36263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5fa9399eeb41d095ef2e27553f8413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71eecc7d13ea4bf095db0797e82aa5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1af9f52ecc943dcbbeb958c4cc95df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed81990eeb144e8f82de84e32efd0e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e3680fd03a4e9682ec949c298a9bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushovitNanda/SemEval-Food-Hazards/blob/main/DistilBert_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jDzab_pA8O32"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets --upgrade\n",
        "#!pip install torch\n",
        "import datasets\n",
        "import os\n",
        "import pandas as pd\n",
        "!pip install evaluate\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments, DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_train.csv\n",
        "!wget https://raw.githubusercontent.com/SushovitNanda/SemEval-Food-Hazards/main/Datasets/incidents_val.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OlIsXLeV8RKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hazard-Category"
      ],
      "metadata": {
        "id": "W-LRFDqN8eF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input data\n",
        "train['input_text'] = train['title'] + \" \" + train['text']\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['label'] = label_encoder.fit_transform(train['hazard-category'])\n",
        "\n",
        "# Train-test split using stratification\n",
        "train_df, test_df = train_test_split(\n",
        "    train[['input_text', 'label']],\n",
        "    test_size=0.2,\n",
        "    stratify=train['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert the dataframes into Hugging Face's Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define a tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set up a data collator to pad inputs dynamically\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load RoBERTa model for sequence classification\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", num_labels=num_labels, ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "id": "Kmhoevgm8RHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the F1 metric and specify macro averaging\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define the compute_metrics function to maximize F1 macro average\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Compute the F1 macro average\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# Update training arguments to focus on F1 score\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score as the metric for saving best model\n",
        "    greater_is_better=True       # Ensure higher F1 is considered better\n",
        ")\n",
        "\n",
        "# Redefine the Trainer with the updated compute_metrics and early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics  # Use F1 macro for evaluation\n",
        ")\n",
        "\n",
        "# Add EarlyStoppingCallback to the Trainer with patience of 4 epochs\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4))\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "jadXTCNY8RFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Classification report\n",
        "target_names = label_encoder.classes_\n",
        "print(classification_report(test_df['label'], preds, target_names=target_names))"
      ],
      "metadata": {
        "id": "R8fwqeEl8RAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test = pd.read_csv(\"incidents_val.csv\")\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input text\n",
        "test['input_text'] = test['title'] + \" \" + test['text']\n",
        "\n",
        "# Define tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Convert test data to Hugging Face Dataset format\n",
        "test_dataset = Dataset.from_pandas(test[['input_text']])\n",
        "\n",
        "# Tokenize the test dataset\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get the predicted labels (argmax on logits)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Map the numeric predictions back to the original labels\n",
        "predicted_labels = label_encoder.inverse_transform(preds)\n",
        "\n",
        "# Add the predicted labels to the original test DataFrame under 'hazard-category' column\n",
        "test['hazard-category'] = predicted_labels\n",
        "\n",
        "# Save the updated test DataFrame with the predictions to the same CSV\n",
        "test.to_csv(\"submissions.csv\", index=False)\n",
        "print(\"Predictions saved to 'submissions.csv'.\")\n"
      ],
      "metadata": {
        "id": "YYRhwjL_8Q-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product-Category"
      ],
      "metadata": {
        "id": "ZTtHoeT18g06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input data\n",
        "train['input_text'] = train['title'] + \" \" + train['text']\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['label'] = label_encoder.fit_transform(train['product-category'])\n",
        "\n",
        "# Train-test split using stratification\n",
        "train_df, test_df = train_test_split(\n",
        "    train[['input_text', 'label']],\n",
        "    test_size=0.2,\n",
        "    stratify=train['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert the dataframes into Hugging Face's Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define a tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set up a data collator to pad inputs dynamically\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load RoBERTa model for sequence classification\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", num_labels=num_labels, ignore_mismatched_sizes=True)\n"
      ],
      "metadata": {
        "id": "vgeW3mcC8Q70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the F1 metric and specify macro averaging\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define the compute_metrics function to maximize F1 macro average\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Compute the F1 macro average\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# Update training arguments to focus on F1 score\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score as the metric for saving best model\n",
        "    greater_is_better=True       # Ensure higher F1 is considered better\n",
        ")\n",
        "\n",
        "# Redefine the Trainer with the updated compute_metrics and early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics  # Use F1 macro for evaluation\n",
        ")\n",
        "\n",
        "# Add EarlyStoppingCallback to the Trainer with patience of 4 epochs\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4))\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "6aAb7_hm8Q5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Classification report\n",
        "target_names = label_encoder.classes_\n",
        "print(classification_report(test_df['label'], preds, target_names=target_names))"
      ],
      "metadata": {
        "id": "acAYRb6S8jRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test = pd.read_csv(\"incidents_val.csv\")\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input text\n",
        "test['input_text'] = test['title'] + \" \" + test['text']\n",
        "\n",
        "# Define the tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Convert test data to Hugging Face Dataset format\n",
        "test_dataset = Dataset.from_pandas(test[['input_text']])\n",
        "\n",
        "# Tokenize the test dataset\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get the predicted labels (argmax on logits)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Map the numeric predictions back to the original labels\n",
        "predicted_labels = label_encoder.inverse_transform(preds)\n",
        "\n",
        "# Add the predicted labels to the original test DataFrame under 'product-category' column\n",
        "test['product-category'] = predicted_labels\n",
        "\n",
        "# Save the updated test DataFrame with the predictions back to the original CSV\n",
        "test.to_csv(\"submissions.csv\", index=False)\n",
        "print(\"Predictions saved to 'submissions.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vQ7Hd2X48jPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hazard"
      ],
      "metadata": {
        "id": "iW29HNoT8kJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input data\n",
        "train['input_text'] = train['title'] + \" \" + train['text']\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['label'] = label_encoder.fit_transform(train['hazard'])\n",
        "\n",
        "# Train-test split using stratification\n",
        "train_df, test_df = train_test_split(\n",
        "    train[['input_text', 'label']],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert the dataframes into Hugging Face's Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define a tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set up a data collator to pad inputs dynamically\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load RoBERTa model for sequence classification\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", num_labels=num_labels, ignore_mismatched_sizes=True)\n"
      ],
      "metadata": {
        "id": "96r1cWwc8jMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the F1 metric and specify macro averaging\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define the compute_metrics function to maximize F1 macro average\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Compute the F1 macro average\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# Update training arguments to focus on F1 score\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score as the metric for saving best model\n",
        "    greater_is_better=True       # Ensure higher F1 is considered better\n",
        ")\n",
        "\n",
        "# Redefine the Trainer with the updated compute_metrics and early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics  # Use F1 macro for evaluation\n",
        ")\n",
        "\n",
        "# Add EarlyStoppingCallback to the Trainer with patience of 4 epochs\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4))\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "0eIWDmOi8jJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Classification report\n",
        "unique_labels = np.unique(test_df['label'])\n",
        "filtered_target_names = [target_names[i] for i in unique_labels if i < len(target_names)]\n",
        "\n",
        "print(classification_report(test_df['label'], preds, labels=unique_labels, target_names=filtered_target_names))"
      ],
      "metadata": {
        "id": "0dhvk3Qk8jHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test = pd.read_csv(\"incidents_val.csv\")\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input text\n",
        "test['input_text'] = test['title'] + \" \" + test['text']\n",
        "\n",
        "# Define the tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Convert test data to Hugging Face Dataset format\n",
        "test_dataset = Dataset.from_pandas(test[['input_text']])\n",
        "\n",
        "# Tokenize the test dataset\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get the predicted labels (argmax on logits)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Map the numeric predictions back to the original labels\n",
        "predicted_labels = label_encoder.inverse_transform(preds)\n",
        "\n",
        "# Add the predicted labels to the original test DataFrame under 'product-category' column\n",
        "test['hazard'] = predicted_labels\n",
        "\n",
        "# Save the updated test DataFrame with the predictions back to the original CSV\n",
        "test.to_csv(\"submissions.csv\", index=False)\n",
        "print(\"Predictions saved to 'submissions.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5hjQPT758jEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product"
      ],
      "metadata": {
        "id": "ck12ALIM8l4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('incidents_train.csv')\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input data\n",
        "train['input_text'] = train['title'] + \" \" + train['text']\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['label'] = label_encoder.fit_transform(train['product'])\n",
        "\n",
        "# Train-test split using stratification\n",
        "train_df, test_df = train_test_split(\n",
        "    train[['input_text', 'label']],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert the dataframes into Hugging Face's Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define a tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set up a data collator to pad inputs dynamically\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load RoBERTa model for sequence classification\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", num_labels=num_labels, ignore_mismatched_sizes=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1a8485737d34406ea9959acf57a23a70",
            "f9484e451fe2473eb3ef9194d341746d",
            "b4752608eb0e4ac1bba8f35c42030a23",
            "5980f2a795f34aea86a22e92883d4d7b",
            "b7df35aaf2504aa1aa30b185fc160f44",
            "71ffff11c1ec405a98c9f3cd387508fd",
            "7a7aa6f4853a4d59adfd1a7d3789f7d7",
            "e943066a0f4447779812166fc78e4023",
            "0162154dcdef475ab8ff760367f96e26",
            "5778cce64ad74e409f8a3149d17be549",
            "397e49aa76e34c979f771062bbd60860",
            "3b638e322f494714a69798a0eabf99b8",
            "ce2c9f9046d94b65a24e39e24c1b4860",
            "169a615aab0d4b278b59c078d4935ff8",
            "673f280a79514c938dea6d1b8234311c",
            "980fd6ea2121423280a855a90982aff3",
            "4e6e447b10064ad7b9eb2bac06d36263",
            "5c5fa9399eeb41d095ef2e27553f8413",
            "71eecc7d13ea4bf095db0797e82aa5ea",
            "b1af9f52ecc943dcbbeb958c4cc95df6",
            "ed81990eeb144e8f82de84e32efd0e66",
            "b8e3680fd03a4e9682ec949c298a9bec"
          ]
        },
        "collapsed": true,
        "id": "_AtRw0jj8jCG",
        "outputId": "101fae83-dfc9-4ded-eb9d-cf828a5153f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4065 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a8485737d34406ea9959acf57a23a70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1017 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b638e322f494714a69798a0eabf99b8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the F1 metric and specify macro averaging\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define the compute_metrics function to maximize F1 macro average\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Compute the F1 macro average\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "    return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# Update training arguments to focus on F1 score\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score as the metric for saving best model\n",
        "    greater_is_better=True       # Ensure higher F1 is considered better\n",
        ")\n",
        "\n",
        "# Redefine the Trainer with the updated compute_metrics and early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics  # Use F1 macro for evaluation\n",
        ")\n",
        "\n",
        "# Add EarlyStoppingCallback to the Trainer with patience of 4 epochs\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4))\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3_HTPZqP8i_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Classification report\n",
        "unique_labels = np.unique(test_df['label'])\n",
        "filtered_target_names = [target_names[i] for i in unique_labels if i < len(target_names)]\n",
        "\n",
        "print(classification_report(test_df['label'], preds, labels=unique_labels, target_names=filtered_target_names))"
      ],
      "metadata": {
        "id": "6atW7gqS8i84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test = pd.read_csv(\"incidents_val.csv\")\n",
        "\n",
        "# Combine 'title' and 'text' columns to create input text\n",
        "test['input_text'] = test['title'] + \" \" + test['text']\n",
        "\n",
        "# Define the tokenization function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['input_text'], truncation=True)\n",
        "\n",
        "# Convert test data to Hugging Face Dataset format\n",
        "test_dataset = Dataset.from_pandas(test[['input_text']])\n",
        "\n",
        "# Tokenize the test dataset\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get the predicted labels (argmax on logits)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Map the numeric predictions back to the original labels\n",
        "predicted_labels = label_encoder.inverse_transform(preds)\n",
        "\n",
        "# Add the predicted labels to the original test DataFrame under 'product-category' column\n",
        "test['product'] = predicted_labels\n",
        "\n",
        "# Save the updated test DataFrame with the predictions back to the original CSV\n",
        "test.to_csv(\"submissions.csv\", index=False)\n",
        "print(\"Predictions saved to 'submissions.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UjmMcW_m8Q2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZ3LolxbEmps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}